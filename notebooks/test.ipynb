{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG=false\n"
     ]
    }
   ],
   "source": [
    "import { load } from \"std/dotenv/mod.ts\";\n",
    "\n",
    "const env: Record<string, string> = await load({ envPath: \"../.env\" });\n",
    "\n",
    "console.log(`DEBUG=${env.DEBUG}`);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Mongo Client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints\n"
     ]
    }
   ],
   "source": [
    "import { MongoClient } from \"mongodb\";\n",
    "\n",
    "const MONGO_URI = env.MONGO_URI;\n",
    "\n",
    "export const client = new MongoClient(MONGO_URI);\n",
    "\n",
    "export const collection = client.db().collection(\"checkpoints\");\n",
    "\n",
    "console.log(collection.collectionName);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import { OpenAIEmbeddings } from \"@langchain/openai\";\n",
    "\n",
    "const { OPENAI_API_KEY } = env;\n",
    "\n",
    "// Initialize embeddings model\n",
    "export const embeddings1024 = new OpenAIEmbeddings({\n",
    "  model: \"text-embedding-3-small\",\n",
    "  dimensions: 1024,\n",
    "  apiKey: OPENAI_API_KEY,\n",
    "});\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create checkpointer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { MongoClient, Collection } from \"mongodb\";\n",
    "\n",
    "import {\n",
    "  BaseMessage,\n",
    "  SystemMessage,\n",
    "  ToolMessage,\n",
    "} from \"@langchain/core/messages\";\n",
    "import { RunnableConfig } from \"@langchain/core/runnables\";\n",
    "\n",
    "import {\n",
    "  BaseCheckpointSaver,\n",
    "  Checkpoint,\n",
    "  CheckpointMetadata,\n",
    "  CheckpointTuple,\n",
    "} from \"npm:@langchain/langgraph@0.0.26\";\n",
    "\n",
    "const { MONGO_URI } = env;\n",
    "\n",
    "const CustomSerializer = {\n",
    "  stringify(obj: CheckpointRecord) {\n",
    "    return obj;\n",
    "  },\n",
    "\n",
    "  async parse(data: Checkpoint | string) {\n",
    "    return typeof data === \"string\" ? JSON.parse(data) : data;\n",
    "  },\n",
    "};\n",
    "\n",
    "interface CheckpointRecord {\n",
    "  checkpoint: string;\n",
    "  metadata: string;\n",
    "  parent_id?: string;\n",
    "  thread_id: string;\n",
    "  checkpoint_id: string;\n",
    "  embedding: number[];\n",
    "  history: string;\n",
    "  timestamp: Date;\n",
    "}\n",
    "\n",
    "export class MongoSaver extends BaseCheckpointSaver {\n",
    "  private client: MongoClient;\n",
    "  private isSetup: boolean;\n",
    "  public collection: Collection<CheckpointRecord>;\n",
    "\n",
    "  constructor(client: MongoClient) {\n",
    "    super(CustomSerializer);\n",
    "    this.client = client;\n",
    "    this.collection = this.client.db().collection(\"checkpoints\");\n",
    "    this.isSetup = false;\n",
    "  }\n",
    "\n",
    "  static fromConnString(connString: string = MONGO_URI || \"\"): MongoSaver {\n",
    "    return new MongoSaver(new MongoClient(connString));\n",
    "  }\n",
    "\n",
    "  private async setup(): Promise<void> {\n",
    "    if (this.isSetup) return;\n",
    "\n",
    "    try {\n",
    "      await this.collection.findOne();\n",
    "      this.isSetup = true;\n",
    "    } catch (error) {\n",
    "      console.error(\"Error querying checkpoints collection\", error);\n",
    "      throw error;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // below 3 methods are necessary for any checkpointer implementation: getTuple, list and put\n",
    "  async getTuple(config: RunnableConfig): Promise<CheckpointTuple | undefined> {\n",
    "    await this.setup();\n",
    "    const { thread_id, checkpoint_id } = config.configurable || {};\n",
    "\n",
    "    try {\n",
    "      if (checkpoint_id) {\n",
    "        const res = await this.collection.findOne({ thread_id, checkpoint_id });\n",
    "\n",
    "        if (res) {\n",
    "          return {\n",
    "            config,\n",
    "            checkpoint: (await this.serde.parse(res.checkpoint)) as Checkpoint,\n",
    "            metadata: (await this.serde.parse(\n",
    "              res.metadata\n",
    "            )) as CheckpointMetadata,\n",
    "            parentConfig: res.parent_id\n",
    "              ? {\n",
    "                  configurable: {\n",
    "                    thread_id,\n",
    "                    checkpoint_id: res.parent_id,\n",
    "                  },\n",
    "                }\n",
    "              : undefined,\n",
    "          };\n",
    "        }\n",
    "      } else {\n",
    "        const res = await this.collection.findOne(\n",
    "          { thread_id },\n",
    "          { sort: { timestamp: -1 } }\n",
    "        );\n",
    "\n",
    "        if (res) {\n",
    "          return {\n",
    "            config: {\n",
    "              configurable: {\n",
    "                thread_id: res.thread_id,\n",
    "                checkpoint_id: res.checkpoint_id,\n",
    "              },\n",
    "            },\n",
    "            checkpoint: (await this.serde.parse(res.checkpoint)) as Checkpoint,\n",
    "            metadata: (await this.serde.parse(\n",
    "              res.metadata\n",
    "            )) as CheckpointMetadata,\n",
    "            parentConfig: res.parent_id\n",
    "              ? {\n",
    "                  configurable: {\n",
    "                    thread_id: res.thread_id,\n",
    "                    checkpoint_id: res.parent_id,\n",
    "                  },\n",
    "                }\n",
    "              : undefined,\n",
    "          };\n",
    "        }\n",
    "      }\n",
    "    } catch (error) {\n",
    "      console.error(\"Error retrieving checkpoint\", error);\n",
    "      throw error;\n",
    "    }\n",
    "\n",
    "    return undefined;\n",
    "  }\n",
    "\n",
    "  async *list(\n",
    "    config: RunnableConfig,\n",
    "    limit?: number,\n",
    "    before?: RunnableConfig\n",
    "  ): AsyncGenerator<CheckpointTuple> {\n",
    "    await this.setup();\n",
    "    const { thread_id } = config.configurable || {};\n",
    "    let query: Record<string, unknown> = { thread_id };\n",
    "\n",
    "    const params: (string | number)[] = [thread_id];\n",
    "    if (before?.configurable?.checkpoint_id) {\n",
    "      query = {\n",
    "        ...query,\n",
    "        checkpoint_id: { $lt: before.configurable.checkpoint_id },\n",
    "      };\n",
    "      params.push(before.configurable.checkpoint_id);\n",
    "    }\n",
    "    let options: Record<string, unknown> = { checkpoint_id: -1 };\n",
    "    if (limit) {\n",
    "      query.limit = params.length + 1;\n",
    "      params.push(limit);\n",
    "    }\n",
    "\n",
    "    try {\n",
    "      const res = await this.collection.find(query, options).toArray();\n",
    "      for (const row of res) {\n",
    "        yield {\n",
    "          config: {\n",
    "            configurable: {\n",
    "              thread_id: row.thread_id,\n",
    "              checkpoint_id: row.checkpoint_id,\n",
    "            },\n",
    "          },\n",
    "          checkpoint: (await this.serde.parse(row.checkpoint)) as Checkpoint,\n",
    "          metadata: (await this.serde.parse(\n",
    "            row.metadata\n",
    "          )) as CheckpointMetadata,\n",
    "          parentConfig: row.parent_id\n",
    "            ? {\n",
    "                configurable: {\n",
    "                  thread_id: row.thread_id,\n",
    "                  checkpoint_id: row.parent_id,\n",
    "                },\n",
    "              }\n",
    "            : undefined,\n",
    "        };\n",
    "      }\n",
    "    } catch (error) {\n",
    "      console.error(\"Error listing checkpoints\", error);\n",
    "      throw error;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  async put(\n",
    "    config: RunnableConfig,\n",
    "    checkpoint: Checkpoint,\n",
    "    metadata: CheckpointMetadata\n",
    "  ): Promise<RunnableConfig> {\n",
    "    await this.setup();\n",
    "    try {\n",
    "      const messages =\n",
    "        (checkpoint?.channel_values?.messages as BaseMessage[]) || [];\n",
    "      const lastMessage = messages?.[messages?.length - 1] || {};\n",
    "\n",
    "      let text: string;\n",
    "\n",
    "      if (lastMessage.content instanceof Array) {\n",
    "        const message: Record<string, unknown> =\n",
    "          lastMessage.content.find((message) => message.type === \"text\") || {};\n",
    "        text = message?.text as string;\n",
    "      } else {\n",
    "        text = lastMessage.content;\n",
    "      }\n",
    "\n",
    "      if (text) {\n",
    "        const embeddings = await embeddings1024.embedDocuments([text]);\n",
    "\n",
    "        const update: CheckpointRecord = {\n",
    "          thread_id: config?.configurable?.thread_id,\n",
    "          checkpoint_id: checkpoint.id,\n",
    "          parent_id: config?.configurable?.checkpoint_id,\n",
    "          checkpoint: this.serde.stringify(checkpoint),\n",
    "          metadata: this.serde.stringify(metadata),\n",
    "          embedding: embeddings[0] || [],\n",
    "          history: text,\n",
    "          timestamp: new Date(),\n",
    "        };\n",
    "\n",
    "        await this.collection.insertOne(update);\n",
    "      }\n",
    "    } catch (error) {\n",
    "      console.error(\"Error saving checkpoint\", error);\n",
    "      throw error;\n",
    "    }\n",
    "\n",
    "    return {\n",
    "      configurable: {\n",
    "        thread_id: config.configurable?.thread_id,\n",
    "        checkpoint_id: checkpoint.id,\n",
    "      },\n",
    "    };\n",
    "  }\n",
    "\n",
    "  async closeConnection(): Promise<void> {\n",
    "    await this.client.close();\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add vector store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { MongoDBAtlasVectorSearch } from \"npm:@langchain/mongodb@^0.0.4\";\n",
    "\n",
    "export const vectorStore = new MongoDBAtlasVectorSearch(embeddings1024, {\n",
    "  collection: collection,\n",
    "  indexName: \"default\",\n",
    "  textKey: \"messages.content\",\n",
    "  embeddingKey: \"embedding\",\n",
    "});\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize State\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "import { StateGraphArgs } from \"@langchain/langgraph\";\n",
    "\n",
    "// Define the state interface\n",
    "interface AgentState {\n",
    "  messages: HumanMessage[];\n",
    "}\n",
    "\n",
    "// Define the graph state\n",
    "const graphState: StateGraphArgs<AgentState>[\"channels\"] = {\n",
    "  messages: {\n",
    "    value: (x: HumanMessage[], y: HumanMessage[]) => x.concat(y),\n",
    "    default: () => [],\n",
    "  },\n",
    "};\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { z } from \"zod\";\n",
    "import { DynamicStructuredTool } from \"@langchain/core/tools\";\n",
    "import { TavilySearchResults } from \"@langchain/community/tools/tavily_search\";\n",
    "import { ToolNode } from \"@langchain/langgraph/prebuilt\";\n",
    "\n",
    "const { TAVILY_API_KEY } = env;\n",
    "\n",
    "const searchTool = new TavilySearchResults({\n",
    "  maxResults: 1,\n",
    "  apiKey: TAVILY_API_KEY,\n",
    "});\n",
    "\n",
    "export const historyTool = new DynamicStructuredTool({\n",
    "  name: \"get_history\",\n",
    "  description: \"Use text query to perform vector search against chat history\",\n",
    "  schema: z.object({\n",
    "    query: z.string(),\n",
    "  }),\n",
    "  func: async function ({ query }) {\n",
    "    const embededQuery = await embeddings1024.embedQuery(query);\n",
    "    const res = await vectorStore.similaritySearchVectorWithScore(\n",
    "      embededQuery,\n",
    "      3\n",
    "    );\n",
    "    const history = res\n",
    "      ?.map(\n",
    "        (rec: Array<Record<string, any>>) => rec?.[0]?.metadata.history || \"\"\n",
    "      )\n",
    "      .join(\"; \");\n",
    "    return history;\n",
    "  },\n",
    "});\n",
    "\n",
    "const tools = [historyTool, searchTool];\n",
    "\n",
    "const toolNode = new ToolNode(tools);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { AIMessage } from \"@langchain/core/messages\";\n",
    "import { ChatAnthropic } from \"@langchain/anthropic\";\n",
    "import { END, START, StateGraph } from \"@langchain/langgraph\";\n",
    "\n",
    "const { ANTHROPIC_API_KEY } = env;\n",
    "\n",
    "const model = new ChatAnthropic({\n",
    "  model: \"claude-3-sonnet-20240229\",\n",
    "  temperature: 0,\n",
    "  apiKey: ANTHROPIC_API_KEY,\n",
    "});\n",
    "\n",
    "const boundModel = model.bindTools(tools);\n",
    "\n",
    "// Define the function that determines whether to continue or not\n",
    "function shouldContinue(state: AgentState): \"tools\" | typeof END {\n",
    "  const messages = state.messages;\n",
    "  const lastMessage = messages[messages.length - 1] as AIMessage;\n",
    "\n",
    "  // If the LLM makes a tool call, then we route to the \"tools\" node\n",
    "  if (lastMessage.tool_calls?.length) {\n",
    "    return \"tools\";\n",
    "  }\n",
    "  // Otherwise, we stop (reply to the user)\n",
    "  return END;\n",
    "}\n",
    "\n",
    "// Define the function that calls the model\n",
    "async function callModel(state: AgentState) {\n",
    "  const messages = state.messages;\n",
    "  const response = await boundModel.invoke(messages);\n",
    "\n",
    "  // We return a list, because this will get added to the existing list\n",
    "  return { messages: [response] };\n",
    "}\n",
    "\n",
    "// Define a new graph\n",
    "const workflow = new StateGraph<AgentState>({ channels: graphState })\n",
    "  .addNode(\"agent\", callModel)\n",
    "  .addNode(\"tools\", toolNode)\n",
    "\n",
    "  .addEdge(START, \"agent\")\n",
    "  .addConditionalEdges(\"agent\", shouldContinue)\n",
    "  .addEdge(\"tools\", \"agent\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Chat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ObjectId } from \"mongodb\";\n",
    "import { HumanMessage, SystemMessage } from \"@langchain/core/messages\";\n",
    "import { CompiledStateGraph } from \"@langchain/langgraph\";\n",
    "\n",
    "const threadId = \"conversation-1\";\n",
    "const checkpointer = MongoSaver.fromConnString();\n",
    "\n",
    "let config = {\n",
    "  configurable: {\n",
    "    thread_id: threadId,\n",
    "    checkpoint_id: new ObjectId().valueOf().toString(),\n",
    "  },\n",
    "};\n",
    "\n",
    "const app: CompiledStateGraph<AgentState> = workflow\n",
    "  .compile({ checkpointer })\n",
    "  .withConfig(config);\n",
    "\n",
    "async function writeUserMessage(userMessage: string) {\n",
    "  try {\n",
    "    console.log(\"\\x1b[31m%s\\x1b[0m\", userMessage);\n",
    "\n",
    "    const inputs = {\n",
    "      messages: [\n",
    "        new SystemMessage(\n",
    "          `You are helpful assistent.\\n Please, check current messages state first!\n",
    "          If you miss something try get_history tool to get previous chat history\\n\n",
    "          Prompt it for vector searh.`\n",
    "        ),\n",
    "        new HumanMessage(userMessage),\n",
    "      ],\n",
    "    };\n",
    "\n",
    "    for await (const event of await app.stream(inputs, {\n",
    "      ...config,\n",
    "      streamMode: \"values\",\n",
    "    })) {\n",
    "      const lastMessage = event.messages[event.messages.length - 1];\n",
    "      // console.log(\"\\x1b[32m%s\\x1b[0m\", 'DEBUG', lastMessage)\n",
    "      if (lastMessage.tool_calls?.length === 0) {\n",
    "        // final answer\n",
    "        console.log(\"\\x1b[36m%s\\x1b[0m\", lastMessage.content);\n",
    "      }\n",
    "    }\n",
    "  } catch (e) {\n",
    "    console.log(e);\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mHello. My name is vasily\u001b[0m\n",
      "\u001b[36mNice to meet you Vasily! I'm an AI assistant created by Anthropic. I'm always happy to chat, answer questions, or help out with any tasks you might have. Feel free to ask me about any topics you're interested in or let me know if there's anything specific I can help with.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "await writeUserMessage(\"Hello. My name is vasily\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mwhat was my previous message\u001b[0m\n",
      "\u001b[36mIt seems this conversation just started, so there are no prior messages before you asked \"what was my previous message\". Please let me know if you have any other questions!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "await writeUserMessage(\"what was my previous message\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mwhat is current weather in ny\u001b[0m\n",
      "\u001b[36mAccording to the search results, the current weather in New York City is typical summer weather with high temperatures around 80-90°F (27-32°C) during the day and lows around 75-77°F (24-25°C) at night. The forecast shows mostly sunny and hot conditions which is normal for New York in July.\n",
      "\n",
      "However, since this is a forecast for July 2024, it does not reflect the actual current weather conditions today. To get the latest real-time weather information, I would need to do a more specific search for \"current weather in New York City today\" or check an authoritative weather source like the National Weather Service.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "await writeUserMessage(\"what is current weather in ny\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mdo you remember my name\u001b[0m\n",
      "\u001b[36mAh I see now from the chat history that your name is Vasily. Thank you for letting me check the context - I'll remember that your name is Vasily going forward.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "await writeUserMessage(\"do you remember my name\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mdid i ask about some cities?\u001b[0m\n",
      "\u001b[36mBased on the search results, it looks like you did ask about the weather in New York City, specifically in July 2024. The results show weather forecasts and current conditions for New York City around that time period. Let me know if you need any other details about your previous question on cities!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "await writeUserMessage(\"did i ask about some cities?\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mwhat was my previous question?\u001b[0m\n",
      "\u001b[36mBased on the chat history returned, your previous question was \"did i ask about some cities?\". Please let me know if you need any clarification or have an additional question!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "await writeUserMessage(\"what was my previous question?\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ acknowledged: \u001b[33mtrue\u001b[39m, deletedCount: \u001b[33m23\u001b[39m }"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await collection.deleteMany({});\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
